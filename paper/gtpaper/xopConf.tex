\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{amsmath,amssymb}
\usepackage{array}
% \usepackage{cite}   % importing cite is throwing errors for some reason
\usepackage{color}
\usepackage[inline]{enumitem}
\usepackage{multicol}
\usepackage{float}
\usepackage[shortcuts]{extdash}
% \usepackage[labelfont=bf,textfont=up]{caption}

\usepackage{textcomp}

% Get todos to render properly
\usepackage[obeyFinal]{easy-todo}

% Add package for well rendered quotations
\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage{lambda}

%package to handle table inputs from separate files
\usepackage{filecontents, catchfile}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% macro for angled brackets
\newcommand{\brackets}[1]{$\langle$\ignorespaces#1\unskip$\rangle$}
% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[Baltimore'2018]{SIGCSE}{February 2018}{Baltimore, Maryland USA} 
\acmYear{2018}
\copyrightyear{2017}

\acmPrice{15.00}

% inline alternative separator in grammar definitions
\newcommand{\OR}{\OB{\hspace{1.5ex}|\hspace{1.5ex}}}

% explanation tree stack operation
\newcommand{\Push}{\OB{\Rightarrow}}
\newcommand{\Pop}{\OB{\Leftarrow}}
\newcommand{\PopPush}{\OB{\Leftrightarrow}}

% semantics
\newcommand{\Sem}[1]{\OB{\llbracket#1\rrbracket}}


\begin{document}
\title{A Domain Analysis of Data Structure and Algorithm Explanations in the Wild}


\author{Jeffrey Young} 
\affiliation{%
 \institution{Oregon State University}
 \department{School of EECS}
 \city{Corvallis} 
 \state{Oregon}
 \country{USA}}
\author{Eric Walkingshaw} 
\affiliation{%
 \institution{Oregon State University}
 \department{School of EECS}
 \city{Corvallis} 
 \state{Oregon}
 \country{USA}}
% \author{Anonymized for Review}
% \affiliation{
%   \institution{\phantom{Anonymous}}
%   \department{\phantom{Anonymous}}
%   \city{\phantom{Anonymous}}
%   \state{\phantom{Anonymous}}
%   \country{\phantom{Anonymous}}
% }

\begin{abstract}
%
Explanations of data structures and algorithms are complex interactions of
several notations, including natural language, mathematics, pseudocode, and
diagrams. Currently, such explanations are created ad hoc using a variety of
tools and the resulting artifacts are static, reducing explanatory value. We
envision a domain-specific language for developing rich, interactive
explanations of data structures and algorithms. In this paper, we analyze this
domain to sketch requirements for our language. We perform a grounded theory
analysis to generate a qualitative coding system for explanation artifacts
collected online. This coding system implies a common structure among
explanations of algorithms and data structures. We believe this structure can
be reused as the semantic basis of a domain-specific language for creating
interactive explanation artifacts. This work is part of our effort to develop
the paradigm of explanation-oriented programming, which shifts the focus of
programming from computing results to producing rich explanations of how those
results were computed.
%
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
% \begin{CCSXML}
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}


% \keywords{ACM proceedings, \LaTeX, text tagging}

\maketitle

\section{Introduction}
\label{sec:intro}

Data structures and algorithms are at the heart of computer science and must be
explained to each new generation of students. A pressing question is: How can we
do this effectively?

In this paper, we focus on the \emph{artifacts} that constitute or support
explanations of data structures and algorithms (hereafter just ``algorithms''),
which can be shared and reused.
%
For verbal explanations, such as a lecture, the supporting artifact might be
the associated slides. For written explanations, the artifact is the
explanation as a whole, including the text and any supporting figures.
%
Explanation artifacts associated with algorithms are interesting because they
typically present a complex interaction among many different notations,
including natural language, mathematics, pseudocode, executable code, various
kinds of diagrams, animations, and more.


Currently, explanation artifacts for algorithms are created ad hoc using a
variety of tools and techniques, and the resulting explanations tend to be
static, reducing their explanatory value.
%
Although there has been a substantial amount of work on algorithm
visualization~\cite{Gloor92,Gloor97,HDS02,shaffer2010algorithm,HANSEN2002291,KANN1997223},
and tools exist for creating these kinds of supporting artifacts, there is no
good solution for creating integrated, multi-notational explanations as a
whole. Similarly, although some algorithm visualization tools provide a means
for the student to tweak the parameters or inputs to an algorithm to generate
new visualizations, they do not support creating cohesive interactive
explanations that correspondingly modify the surrounding explanation or
allow the student to respond to or query the explanation in other ways.
%
To fill this gap, we envision a \emph{domain-specific language} (DSL) that
supports the creation of rich, interactive, multi-notational artifacts for
explaining algorithms.
%
The development of this DSL is part of an effort to explore the new paradigm of
\emph{explanation-oriented programming}, described in
Section~\ref{sec:back:xop}.


The intended users of the envisioned DSL are CS educators who want to create
\emph{interactive artifacts} to support the explanation of algorithms. These
users are experts on the corresponding algorithms and also skilled
programmers. The produced explanation artifacts might supplement a lecture or
be posted to a web page as a self-contained (textual and graphical)
explanation.
%
The DSL should support pedagogical methods through built-in
abstractions and language constructs. It should also support a variety of forms
of student interaction. For example, teachers should be able to define
equivalence relations enabling users to automatically generate variant
explanations~\cite{EW13jvlc}, to build in responses to anticipated
questions, and to provide explanations at multiple levels of abstraction.


This paper presents a formative step toward this vision. We conduct a
\emph{qualitative analysis} of our domain to determine the form and content of
the explanation artifacts that educators are already creating.
%
Specifically, we answer the following research questions:
%
\begin{enumerate}[label=RQ\arabic*.,ref=RQ\arabic*,leftmargin=*]

\item \label{rq:parts}
%
What are the component parts of an algorithm explanation?

\item \label{rq:structure}
%
How are the parts of an algorithm explanation structured?

\item \label{rq:notations}
%
What kinds of notations are used in algorithm explanations?

\end{enumerate}
%
Answering these questions establishes expressiveness requirements for our DSL
since we should be able to express at least explanations of the kinds educators
are already creating. They also help to guide the design of the DSL by
establishing an initial set of components and operations for building
explanations.
%
We base our analysis on the established qualitative research method of
\emph{grounded theory}~\cite{Strauss67discoveryof}, which we describe in
Section~\ref{sec:back:gt}.


For our analysis, we collected 15 explanation artifacts from the internet, as
described in Section~\ref{sec:exp:setup}. These artifacts are lecture notes
that explain two algorithms and one data structure commonly covered in
undergraduate computer science courses: Dijkstra's shortest path
algorithm~\cite[pp.~137--142]{KT06}, merge sort~\cite[210--214]{KT06}, and AVL
trees~\cite[pp.~458--475]{KnuthArt3}.
%
Through the application of grounded theory, we develop a coding system that
captures the components, structure, and notations of the explanation in each
document. This paper makes the following contributions:
%
\begin{enumerate}[label=C\arabic*.,ref=C\arabic*,leftmargin=*]


\item \label{contrib:codes}
%
We provide a \emph{coding system} (Section~\ref{sec:res:sys}) for analyzing
explanation artifacts in the form of lecture notes. We show that through the
application of the coding system, each artifact, regardless of content, author,
or institution, forms a tree structure, which we have termed an
\emph{explanation tree} (Section~\ref{sec:res:xopTree}).

\item \label{contrib:data}
%
We provide a coded qualitative data set of explanation artifacts, using the
system defined in \ref{contrib:codes}, applied to our sample of 15 collected
explanation artifacts, along with a tool for exploring and visualizing this
data set (Section~\ref{sec:res:data}).

\item \label{contrib:DSL}
%
We describe how our coding system and explanation trees can provide a semantic
basis for a DSL and argue for the advantages of such an approach
(Section~\ref{sec:dis}).
%
\end{enumerate}

\noindent

\section{Background And Related Work}
\label{sec:back}

In this section, we put our work into context.
%
In Section~\ref{sec:back:xop}, we describe the paradigm of explanation-oriented
programming, which is the underlying motivation for our work.
%
In Section~\ref{sec:back:gt}, we describe the grounded theory methodology that
we used to develop our coding system.
%
And in Section~\ref{sec:back:rw}, we briefly discuss other work related to
teaching algorithms.


\subsection{Explanation-Oriented Programming}
\label{sec:back:xop}

Explanation-oriented programming (XOP) is a programming paradigm where the
primary output of a program is not a set of computed values, but an
\emph{explanation of how} those values were
computed~\cite{EW08vl,EW09dsl,EW09vl,WE11dsl,EW13jvlc}.
%
A high-level goal of this work is to further realize the paradigm of XOP
through the development of a specific DSL.


Programming languages for XOP should not merely produce explanations as a
byproduct, but should provide abstractions and features specific to the
creation of interactive explanation artifacts. For example, they should provide
facilities for creating application-specific notations and visualizations
(which are widespread in explanations of algorithms), and for describing
alternative explanations produced in response to user input, for example, at
different levels of abstraction, by parameterization, or generated by
explanation equivalence laws~\cite{EW13jvlc}. Additionally, languages for XOP
should help guide the programmer toward the creation of \emph{good}
explanations.


The need for interactive explanation artifacts is motivated by the observation
that there is a trade-off between personal explanations and traditional
explanation artifacts, which can be partially bridged by XOP programs viewed as
rich, interactive explanation artifacts.
%
A good \emph{personal explanation} is useful because the explainer can
\emph{respond} to the student, adjusting the pace and strategy as necessary.
For example, the teacher can answer questions, rephrase parts of an
explanation, and provide additional examples as needed.
%
Unfortunately, good personal explanations are a scarce resource. First, there
are limited number of people who can provide high quality personal explanations
on a topic. Second, a personal explanation is usually ephemeral and so cannot
be directly shared or reused.
%
Since personal explanations are hard to come by, many students learn from
\emph{impersonal explanation artifacts}, such as recorded lectures, textbooks
and online written and graphical resources.
%
These impersonal explanations lack the interaction and adaptability of personal
explanations, but have the advantage of being easy to massively share and reuse
via libraries and the internet.


In-person lectures, such as in many undergraduate computer science programs,
exist at a midway point between impersonal and personal explanations, perhaps
closer to the personal end of the spectrum. These \emph{classroom explanations}
are adaptable---students can ask questions in class, the teacher can respond,
and explanations can be adapted on the fly if students are confused---but they
are not as adaptable as personal explanations since the teacher must
accommodate many students at once. Classroom explanations are more efficient
than personal explanations since they are shared amongst many students, but not
as efficient as impersonal explanations since they are still ephemeral and
therefore difficult to reuse.


We target another midway point, closer to the impersonal end of the spectrum,
of \emph{interactive explanation artifacts} that attempt to reproduce the
responsiveness and adaptability of personal explanations, but which can still
be shared and reused online. Such explanation artifacts would be expensive to
produce with current tools since an \emph{explanation designer} must not only
create a high quality initial explanation and corresponding visualizations, but
also anticipate and explicitly program responses to queries by the student.
%
We expect that DSLs for XOP can help alleviate this burden.


\subsection{Grounded Theory}
\label{sec:back:gt}

%% What is it
The core idea of grounded theory is to generate or discover a theory
inductively, based on data, rather than the usual scientific approach of using
data to evaluate a theory developed a priori. 
%
Grounded theory is rooted in a pragmatist view that theory should target
its intended uses~\cite{Strauss67discoveryof}.
%
% uses vis-a-viz logico-deductive theories which are concerned with what can be
% expressed by the theory~\cite{Strauss67discoveryof}. As Glaser and Strauss
% state:
%
% \say{A grounded theory is one that is inductively derived from the study of
% the phenomena it represents}.
%
% Like any methodology, grounded theory employs a specific vocabulary to refer
% to phases of research. The rest of this section will introduce grounded
% theory terminology in concert with an operational example that will show how
% one may perform a grounded theory analysis.
%
This subsection briefly outlines the grounded theory methodology from
\citet{corbin2014basics} used in our study.


The first task in grounded theory is to collect initial data from the subject
one wishes to study. For example, a researcher who wants to find out why some
students drop out of computer science programs might conduct interviews with
students, and collect student schedules and homework assignments.
%
Once some data is collected, the researcher begins \emph{coding}, which is the
process of assigning descriptive tags to qualitative data.


Coding consists of three stages:
%
\begin{enumerate*}
%
\item During \emph{open coding}, the researcher writes down \emph{any} terms
that describe the data.
%
\item During \emph{axial coding}, the researcher identifies similarities and
other relationships between tags developed during open coding. The goal of this
step is to develop a \emph{coding paradigm}, which is a model that describes
the inter-relationship of tags.
%
\item Finally, during \emph{selective coding}, the identifies a small set of
core tags that capture the main concepts and relationships identified during
axial coding. These tags form the basis of the theory extracted from the data.
%
\end{enumerate*}


In grounded theory, data collection and analysis occurs simultaneously and
iteratively. That is, after forming an initial theory, new data will be added
that might provide new tags during open coding, which will suggest revisions to
the theory developed through axial and selective coding, which will trigger a
re-analysis of old data, and so on.
%
This movement back-and-forth between data collection, analysis, and theory
building is a marked departure from quantitative methods where phases are
distinct~\cite{Strauss67discoveryof}.


How does the researcher know when the theory is adequate and when to stop
collecting and coding new data? There are three tenets that can help answer
that question, and which are pivotal to the validity of the grounded theory
method~\cite{Strauss67discoveryof}.
%
\begin{enumerate*}
%
\item The tenet of \emph{constant comparison} is that during all phases of
coding, the researcher must constantly return to earlier data to check whether
tags are applied consistently.
%
\item The tenet of \emph{theoretical sampling} focuses on filling perceived
gaps in the data based on the current theory. For example, we chose to analyze
explanations of algorithms operating on three different underlying data types:
lists, trees, and graphs. After analyzing explanations of merge sort,
explanations of other sorting algorithms have less theoretical sampling value
than explanations of a very different kind of algorithm.
%
\item The tenet of \emph{saturation} helps determine when to stop collecting
and coding new data. Saturation occurs when the coding system is able to
accommodate new data without modification. That is, when the theory can
accurately describe data that was \emph{not} used to generate it. The amount of
data needed to reach this point will vary depending on the topic, research
questions, and individual researchers.
%
\end{enumerate*}


\subsection{Teaching Algorithms through Artifacts}
\label{sec:back:rw}

% \todo{eric double check these references, most have over 100 citations, but I
%   didn't dive too deep into AV (alg vis) work because adding each reference
%   limits our space even more}

Our underlying motivation is to create artifacts that help explain algorithms.
This motivation is shared by a long tradition of researchers working on
algorithm
visualization~\cite{Gloor92,Gloor97,HDS02,shaffer2010algorithm,HANSEN2002291,
Naps:2002:ERV:782941.782998,Grissom:2003:AVC:774833.774846,KANN1997223}.
%
This work is complementary to our goal since a visualization might be one part
of a comprehensive, multi-notational explanation of an algorithm.
%
% Although our formative study considers only static explanations, our goal is to
% design a DSL that enables the creation of interactive explanation artifacts.
% Work on using puzzles~\cite{Levitin:2002:UPT:563517.563456}.
%
Although our formative study considers only static explanations in the form of
lecture notes, our ultimate goal is to design a DSL that enables the creation
of interactive explanation artifacts that realize some of the benefits of
personal explanations. Others have demonstrated that interactivity makes video
lectures a more effective pedagogical
tool~\cite{Schwan2004293,Merkt2011687,zhang2005interactive}.

% Our approach differs from other approaches~\cite{brecht2012learning,
% brecht2008enabling} to explaining algorithms, but shares many important
% features of those approaches. Algorithm visualizations and internet based
% lectures have the property of being random access i.e.\ the user may move
% forward, backward, jump around, and increase or decrease the pace, of the
% lecture at will. This property has shown to be a very effective pedagogical
% tool~\cite{cardall2008live, zhang2005interactive, zhang2006instructional,
% Schwan2004293, Merkt2011687}.
%
% While such a property ultimately comes down to the implementation of the DSL,
% we believe that the work presented here directly supports such beneficial
% aspects of previous work such as random-access and interactivity.


\section{Experimental Setup}
\label{sec:exp:setup}

In this section we describe how we executed the grounded theory process
outlined in Section~\ref{sec:back:gt}.
%
We restricted the scope of data collection to include only lecture notes
produced by faculty/instructors in computer science departments at respected
universities. Furthermore, we restrict our data to include only static, written
documents. Restricting the scope in this way has two benefits:
%
\begin{enumerate*}
%
\item All explanatory artifacts share an intrinsic goal to communicate the
mechanics, application, or implementation of some common computer science
algorithm.
%
\item There are many and varied examples of different approaches to explain the
same algorithm, and many examples of similar approaches to explain different
algorithms.
%
% \item All explanatory artifacts form isolated environments in which an
%   explanation occurs i.e. all artifacts, by virtue of being static and written,
%   must communicate in a restricted manner. In contrast, an oral explanation may
%   use tone, intonation and other forms of explanation to accentuate the
%   explanation. Including such data would complicate the
%
% \todo{fix this}
% \item The data is similar in form to the envisioned dsl i.e. the dsl is
%   envisioned as being directed towards an audience whose means of interaction
%   with it is by text. In contrast, if oral, or video explanations were included
%   than some amount of translation would be required. Although this is not
%   unreasonable it is outside the scope of this analysis.
  
\end{enumerate*}
%
All data collected was either in PDF format, or in HTML format and converted to
PDF. We considered only self-contained lecture notes, excluding slides which we
considered to be incomplete explanations without the associated presentation
they support. 
%
We made no attempt to restrict the size of the data collected. The smallest
document collected was 1.5 pages and the longest was 18 pages.


All data was collected and coded by hand by the first author with the aid of
Atlast.ti software.\footnote{\url{http://atlasti.com/}}
%
Atlast.ti provides direct support for the grounded theory process by allowing
open coding; easing constant comparison with operations for organizing,
searching, and filtering coded documents; and easing axial and selective coding
with operations for collecting, merging, and revising extent tags.


We focused data collection on three algorithms based on different underlying
data types: Dijkstra's shortest path algorithm on
graphs~\cite[pp.~137--142]{KT06}, merge sort of lists~\cite[210--214]{KT06},
and the AVL tree implementation of balanced binary search
trees~\cite[pp.~458--475]{KnuthArt3}.
%
We achieved saturation during the grounded theory analysis after 11 lecture
notes. As additional validation and to round out our data set, we continued
collecting and coding documents until our sample included 5 lecture notes on
each of the 3 topics, for 15 total explanation artifacts.


Some documents contain explanations of multiple algorithms. In cases where
secondary algorithms are explained as part of the explanation of the target
algorithm (e.g.\ as necessary background), we coded the explanation as usual.
In cases where multiple algorithms are explained in a single document but the
explanations are unconnected, we did not code the others. For example, one
document explaining Dijkstra's algorithm also provided an explanation of
Bellman-Ford's shortest-path algorithm, which we ignored.


% We did not perform the selective coding phase of the grounded theory
% analysis. The goal of this study was to develop a prototype coding system,
% not to develop an overarching, causal theory for these documents, such as one
% would generate in selective coding.



\section{Results}
\label{sec:res}

In this section we present the results of our grounded theory analysis.
%
In Section~\ref{sec:res:data}, we briefly describe the coded data set and a
simple associated tool that we provide.
%
In Section~\ref{sec:res:sys} we describe the coding system produced by the
grounded theory analysis and provide a sample coding to illustrate its use. We
observe that the coding paradigm identified during axial coding is that
explanations are tree structured.
%
In Section~\ref{sec:res:xopTree}, we discuss the tree structure of explanations
and describe how to transform a coded explanation artifact into the
corresponding explanation tree.


\subsection{Data Set and Tool Support}
\label{sec:res:data}

The coded data set is available online.\footnote{Will be made available after
anonymous review.} The coded documents are provided both in the proprietary
Atlast.ti format and in an exported CSV format.
%
Artifacts are indexed according to the algorithm of focus and a simple counter.
For example, the first AVL tree document is named AVT01 and the fifth is named
AVT05.


We also provide a small tool written in Haskell that implements the coding
system described in Section~\ref{sec:res:sys} and the explanation tree
representation described in Section~\ref{sec:res:xopTree}. The tool supports
converting a code sequence into the corresponding explanation tree, and
rendering explanation trees in a 2-dimensional plain-text format (see
Figure~\ref{fig:tree}).
%
We provide the code sequence for each document in the data set in a format
compatible with the tool.


\subsection{The Coding System}
\label{sec:res:sys}

The coding system consists of four finite sets of tags---aspects, moves, roles,
and notations---determined through the grounded theory analysis. Aspects and
moves are summarized in Table~\ref{tbl:codes:main}, roles and notations in
Table~\ref{tbl:codes:dec}.


\begin{table}
% \begin{tabular}{>{\em}rl}
\begin{tabular}{ll}
\input{AspectTable}
\\[-1.5ex]
\input{MoveTable}
\\[-1.5ex]
\end{tabular}
\caption{Overview of all \emph{aspects} and \emph{moves} identified by the grounded theory
analysis. Aspects organize an explanation into its constituent parts while
moves are the specific steps taken to guide the reader toward understanding.}
\label{tbl:codes:main}
\end{table}


An \emph{aspect} tag identifies a constituent part of an algorithm explanation,
that is, \emph{what} is being discussed. Example aspects of an explanation are
the goal of the algorithm, required operations, historical context, advantages
and disadvantages, and implementation details.
%
A \emph{move} tag is always associated with a parent aspect and describes
\emph{how} that aspect is addressed, that is, the step taken by the explainer
to help advance the reader's understanding. For example, by breaking the aspect
into cases, providing an example or proof, or defining a concept. A single
aspect may be explained in several moves. We take the name for this concept
from \citet{bellack1966language}'s notion of a ``pedagogical move''.


\begin{table}
% \begin{tabular}{>{\em}rl}
\begin{tabular}{ll}
\input{RoleTable}
\\[-1.5ex]
\input{NotationTable}
\\[-1.5ex]
\end{tabular}
\caption{Overview of the secondary \emph{roles} and \emph{notations} identified
by the grounded theory analysis. These codes decorate aspect and move codes to
add additional information.}
\label{tbl:codes:dec}
\end{table}


Both aspect and move tags can be decorated by tags describing secondary roles
and notations.
%
A \emph{role} tag modifies a move or aspect to indicate that this part of the
explanation serves some secondary purpose not directly captured by the modified
tag. For example, the Aside role might be attached to a move to indicate that
the given move is an aside that does not directly advance the explanation of
the parent aspect, while the Pedagogical role might indicate that the move
gives advice about how to study an aspect rather than explaining it.
%
A \emph{notation} tag modifies a move or aspect to indicate that this part of
the explanation is presented in some format other than natural language text.
If no notation decorator is provided, the tagged fragment is assumed to be
text.


\begin{figure}
\begin{syntax}
\multicolumn{3}{c}{
  a\in\mathit{Aspect} \quad
  m\in\mathit{Move} \quad
  r\in\mathit{Role} \quad
  n\in\mathit{Notation}} \\
c\in\mathit{Code}
 &::=& \Push~a
 \OR \!\Pop\!
 \OR m
 \OR c+d \\
d\in\mathit{Decorator}
 &::=& r \OR n
\end{syntax}

\vspace{-1.5ex}
\caption{Syntax of codes from grounded theory analysis.}
\label{fig:codes:syntax}
\end{figure}


The syntax of codes in our system is defined by the grammar in
Figure~\ref{fig:codes:syntax}, which refers to the tags defined in
Tables~\ref{tbl:codes:main} and~\ref{tbl:codes:dec}.
%
During axial coding, it was realized that aspects of an explanation are
hierarchically arranged, and that in many cases it is only possible to
understand how a move advances an explanation by considering not only the
parent aspect but also its ancestors.
%
Therefore, the coding system needs a way to capture this hierarchy. To do this,
we introduced structuring elements to our codes for indicating where in the
hierarchy a given aspect sits.
%
A new child aspect $a$ is introduced by a ``push'' code, $\Push\,a$, and we
exit out of this aspect with a corresponding ``pop'' code, $\Pop$. A sibling
aspect can be added to the hierarchy with a pop followed by a push. Since
adding siblings is quite common, we introduce $\PopPush\,a$ as syntactic sugar
for this case.
%
A move tag $m$ is added as a child to the current aspect, which may not be the
most recent aspect named in a code due to intervening pop codes.
%
Finally, secondary roles and notations are unified as \emph{decorators}; a
decorator $d$ can be added to a code $c$ as $c+d$.


\input{sampleCoding}


In Table~\ref{tbl:sample}, we illustrate the application of the coding system
to the beginning of one of the documents in our data set, MS03.
%
The document begins in Row~1 with a header that we code as the root aspect,
representing the algorithm itself. Row~2 addresses a sub-aspect, the merge
operation, which it explains in two moves: a description, and the definition of
an in-vivo term.
%
Row~3 is coded by a pop since the explanation is no longer focused on this
operation, but is defining what merge sort is. This move is decorated by the
sequence notation since it is defined by a sequence of steps.
%
Row~4, referring to a diagram illustrating this definition, further decorates
this move with the cartoon notation.
%
Row~5 concerns the sub-aspect of motivating merge sort, which it does through a
description move that uses (light) mathematical notation.
%
Row~6 introduces the sibling aspect of disadvantages of merge sort, which is
also explained through a description with mathematical notation.



\subsection{Explanation Trees}
\label{sec:res:xopTree}

In the previous section, we described how our analysis revealed a hierarchical
structure that is crucial to understanding how an explanation does its work.
%
We call this hierarchical structure an \emph{explanation tree}. The internal
nodes of an explanation tree are the hierarchy of aspects that an explanation
addresses, while the leaves of the tree are the specific moves taken to explain
these aspects. Both the aspects and moves of an explanation tree can be
decorated by secondary roles and notations.
%
\todo{respond to, there needs to be more explanation than discovered during
  axial coding}
The notion of an explanation tree, discovered during axial coding, became the
\emph{coding paradigm} for our analysis, so we adapted our codes to capture
this structure.


Our coding system can be viewed as a simple stack-based language for
constructing an explanation tree. Figure~\ref{fig:semantics} defines an
interpretation of codes as operations in a stack-based machine that builds an
explanation tree.
%
The semantic domain of codes under this interpretation is an update function on
a stack of trees, represented as a linked list. The $\Push\,a$ code pushes a
node labeled by $a$ with no children to the stack. Note that we use $a$ to
represent both the aspect and the corresponding tree node on the stack. The
$\Pop$ code pops the first two nodes on the stack and adds the first node as a
child of the second. The $m$ code adds the move node $m$ to the stack and then
immediately executes a pop code ($\Pop$) since moves correspond to leaves in
the explanation tree.
%
In this interpretation, we assume that the codes have been preprocessed to
incorporate all decorators into the corresponding nodes.
%
Using the $\Sem{\cdot}$ function we can build an explanation tree from a
sequence of codes by simply left-folding the function over the codes with an
initially empty stack, then executing pop codes until the stack is empty.


\newcommand{\TS}{\mathit{ts}}

\begin{figure}
\[
\begin{array}{r@{}l@{~}l}
\Sem{\cdot}    &            &\,:~ \mathit{Tree}^* \to \mathit{Tree}^* \\
\Sem{\Push\,a} &(\TS)       &= a::\TS \\
\Sem{\Pop}     &(c::p::\TS) &= \mathit{addChild}(c,p)::\TS \\
\Sem{m}        &(\TS)       &= \Sem{\Pop}(m::\TS)
\end{array}
\]
\vspace{-1.5ex}
\caption{Interpreting codes as operations in a stack machine that builds an
explanation tree.}
\label{fig:semantics}
\end{figure}


\begin{figure}
\begin{Verbatim}[fontsize=\small,xleftmargin=2ex]
Aspect Algorithm
+- Aspect Operation
|  +- Move Description
|  `- Move InVivo
+- Move Definition @ [Note Sequence,Note Cartoon]
+- Aspect Motivation
|  `- Move Description @ [Note Mathematics]
`- Aspect Disadvantage
   `- Move Description @ [Note Mathematics]
\end{Verbatim}
\caption{Rendering of the explanation tree produced by the coding of the
beginning of MS03 given in Table~\ref{tbl:sample}.}
\label{fig:tree}
\end{figure}


The Haskell tool provided with the data set implements the transformation from
code sequences to explanation trees. It also provides a way to render
explanation trees. This functionality is illustrated in Figure~\ref{fig:tree},
which renders the explanation tree produced by the code sequence in the coding
sample in Table~\ref{tbl:sample}.


A move at the leaf of an explanation tree can be understood to advance the
reader's understanding of the aspects along the path to a root. For example,
the last description move explains a disadvantage of the algorithm identified
by the root.
%
The linear structure of the original explanation can be recovered by a
pre-order traversal of the explanation tree. 


\section{Discussion}
\label{sec:dis}

This formative study was conducted to better understand the domain of algorithm
and data structure explanations, in order to inform the design of an
explanation-oriented DSL for creating interactive explanation artifacts. In
this section, we interpret the results from Section~\ref{sec:res} in this
context.


At a basic level, the grounded theory analysis reveals a set of concepts that
should be realized by abstractions, constructs, in features of the DSL.
%
The DSL should provide ways to capture all of the various aspects of an
algorithm explanation, including aspects like historical background,
motivation, and advantages/disadvantages that are typically not captured
formally.
%
The DSL should also support a range of more and less formal mechanisms for
advancing an explanation through pedagogical moves. The DSL should provide
formal mechanisms for (semi\=/)automatically generating examples from
implementations, performing case-analyses and derivations, and testing
properties of an algorithm, but also support informal explanatory moves such as
presenting observations and assumptions.
%
The DSL should also provide support for a variety of different notations and
support secondary roles such as asides and caveats.


Explanation trees can serve as an underlying semantic model for the DSL.
%
In an interactive setting, explanation trees provide convenient places (nodes)
to hang extra details about a topic which may be explored or not. Explanation
trees presented as lecture notes enforce a single linear path through this tree
structure, but interactive explanations can provide multiple paths through the
same tree structure corresponding to explanations at different levels of
abstraction and with different focuses. In addition to providing suggested
paths through the tree, we can also allow users to navigate the tree on their
own, exploring more details or alternative explanations where desired.
%
The secondary roles we discovered in existing explanations are evidence that
such supplementary information, that does not directly advance the explanation,
is useful. However, there is a disincentive in a linear explanation to provide
too many extra details that detract from the main line of the explanation.
These concerns would be mitigated in an interactive setting where secondary
details can be explored on-demand and remain out-of-the-way otherwise.


A more speculative application is that our theory could be used to adapt and
remix existing explanations into new ones, targeted at a specific audience or
even an individual user.
%
These existing explanations could be in the form of coded lecture notes or
explanations created in the future using our proposed DSL.
%
By organizing an explanation into its constituent aspects that describe
\emph{what} part of an explanation is doing, and separating this from the moves
that describe \emph{how} it is doing it, it becomes possible to identify in
other explanations alternative ways of explaining the same thing.
%
For example, suppose a user is interacting with an explanation that uses a
programming language she is unfamiliar with or is less formal than she likes; a
system could identify corresponding parts from other explanations that use a
different notation or contains more mathematically-decorated moves. Likewise,
an explanation designer could anticipate such challenges and use such a system
to piece together an initial alternative explanation that can then be refined
to be made more consistent with the rest.
%
This empirical approach to generating alternative explanations can supplement
other strategies explored in previous work, such as generating alternative
explanations from equivalence laws~\cite{EW13jvlc}.

\section{Limitations}
While we believe that the work presented here is a promising foundation for
the explanation-oriented paradigm, there are several limitations to the
results presented here that must be addressed.

Admittedly, our data sample is narrow and focused because it does not include
many other forms of explanation e.g. oral or video explanations. While this was
a purposeful decision, it still limits the impact of the results presented here.

\todo{eric sign off on this statement}
We have expounded on the benefits of explanation trees, but we have said nothing
on \textit{how} explanation trees could be used in practice. We purposefully
leave this as an open question for future work because exploring it requires
consideration of varying implementations which is outside the scope of our
present purposes.

\subsection{The Application of Grounded Theory}
%% Why is grounded theory used for this application? What about Discourse Analysis?
We chose to perform a grounded theory approach because we understood the
qualitative nature of the data, and understood our desired long-term result.
Based on these criteria grounded theory seemed a natural fit for the
application. However, our results are significantly unlike results one would
expect from a grounded theory analysis for two reasons. First, our research
question was, and is, ill fitted for grounded theory. We are interested in the
\textit{structure} of an explanation, not the \textit{relationship} between
constituent parts of an explanation. The basic difference is between a
\textit{how} question and a \textit{why} question. While grounded theory is not
limited to \textit{why} questions, we find that our research question was
sufficiently answered by the coding paradigm identified in
section~\ref{sec:res:sys}. Therefore, this analysis falls short of grounded
theory because the result is not a set of identifiable categories and the
relations between them, rather it is the coding paradigm itself. In essence, our
research question was not complex enough to warrant a full grounded theory
analysis.

%% explain in detail what the central phenomena was during GT

\section{Conclusion}
\label{sec:conc}

This paper has presented a grounded theory analysis of explanations of
algorithms and data structures. The analysis was performed on 15 sets of
lecture notes covering three very different algorithms.
%
The grounded theory analysis yielded a coding paradigm that organizes algorithm
explanations into explanation trees, where internal nodes represent various
aspects of the algorithm to be explained and leaves represent pedagogical moves
that incrementally advance the reader's understanding. The analysis also
enumerated the set of aspects and moves that appeared in our data set and
revealed that explanations exhibit a variety of notations.
%
We make our coded data set publicly available and provide an associated tool
for rendering the explanation tree corresponding to each document and to
support future work based on our coding system.


This study was performed as a formative domain analysis to inform the design of
a DSL for creating interactive explanations of algorithms and data structures.
Explanation trees can provide a good semantic basis for such a language, and
that the enumerated aspects, moves, and roles discovered by the analysis
suggest a suite of useful constructs and abstractions the language should
support and establishes its basic expressiveness requirements.


\bibliography{XOPbib,eric}
\bibliographystyle{ACM-Reference-Format}

\end{document}
