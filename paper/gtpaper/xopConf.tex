\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{amsmath,amssymb}
\usepackage{array}
% \usepackage{cite}   % importing cite is throwing errors for some reason
\usepackage{color}
\usepackage[inline]{enumitem}
\usepackage{multicol}
\usepackage{float}
\usepackage[shortcuts]{extdash}
% \usepackage[labelfont=bf,textfont=up]{caption}

\usepackage{textcomp}

% Get todos to render properly
\usepackage[obeyFinal]{easy-todo}

% Add package for well rendered quotations
\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage{lambda}

%package to handle table inputs from separate files
\usepackage{filecontents, catchfile}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% macro for angled brackets
\newcommand{\brackets}[1]{$\langle$\ignorespaces#1\unskip$\rangle$}
% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference{SIGCSE}{February 2018}{Baltimore, Maryland USA} 
\acmYear{2018}
\copyrightyear{2017}

\acmPrice{15.00}

% inline alternative separator in grammar definitions
\newcommand{\OR}{\OB{\hspace{1.5ex}|\hspace{1.5ex}}}

% explanation tree stack operation
\newcommand{\Push}{\OB{\Rightarrow}}
\newcommand{\Pop}{\OB{\Leftarrow}}
\newcommand{\PopPush}{\OB{\Leftrightarrow}}

% semantics
\newcommand{\Sem}[1]{\OB{\llbracket#1\rrbracket}}


\begin{document}
\title{A Domain Analysis of Data Structure and Algorithm Explanations in the Wild}

\copyrightyear{2018}
\acmYear{2018}
\setcopyright{acmlicensed}
\acmConference[SIGCSE'18]{The 49th ACM Technical Symposium on Computing Science Education}{February 21--24, 2018}{Baltimore, MD, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3159450.3159477}
\acmISBN{978-1-4503-5103-4/18/02}


% \begin{CCSXML}
% <ccs2012>
% <concept>
% <concept_id>10003456.10003457.10003527.10003531.10003533</concept_id>
% <concept_desc>Social and professional topics~Computer science education</concept_desc>
% <concept_significance>500</concept_significance>
% </concept>
% </ccs2012>
% \end{CCSXML}
% 
% \ccsdesc[500]{Social and professional topics~Computer science education}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003456.10003457.10003527</concept_id>
<concept_desc>Social and professional topics~Computing education</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Social and professional topics~Computing education}


\author{Jeffrey Young} 
\affiliation{%
 \institution{Oregon State University}
 \department{School of EECS}
 \city{Corvallis} 
 \state{Oregon}
 \country{USA}}
\author{Eric Walkingshaw} 
\affiliation{%
 \institution{Oregon State University}
 \department{School of EECS}
 \city{Corvallis} 
 \state{Oregon}
 \country{USA}}

\begin{abstract}
%
Explanations of data structures and algorithms are complex interactions of
several notations, including natural language, mathematics, pseudocode, and
diagrams. Currently, such explanations are created ad hoc using a variety of
tools and the resulting artifacts are static, reducing explanatory value. We
envision a domain-specific language for developing rich, interactive
explanations of data structures and algorithms. In this paper, we analyze this
domain to sketch requirements for our language. We perform a grounded theory
analysis to generate a qualitative coding system for explanation artifacts
collected online. This coding system implies a common structure among
explanations of algorithms and data structures. We believe this structure can
be reused as the semantic basis of a domain-specific language for creating
interactive explanation artifacts. This work is part of our effort to develop
the paradigm of explanation-oriented programming, which shifts the focus of
programming from computing results to producing rich explanations of how those
results were computed.
%
\end{abstract}

\keywords{explanation-oriented programming; domain-specific languages;
grounded theory; algorithm explanation}

\maketitle

\section{Introduction}
\label{sec:intro}

Data structures and algorithms are at the heart of computer science and must be
explained to each new generation of students. How can we do this effectively?
%
In this paper, we focus on the \emph{artifacts} that constitute or support
explanations of data structures and algorithms (hereafter just ``algorithms''),
which can be shared and reused.
%
For verbal explanations, such as a lecture, the supporting artifact might be
the associated slides. For written explanations, the artifact is the
explanation as a whole, including the text and any supporting figures.
%
Explanation artifacts for algorithms are interesting because they typically
present a complex interaction among many different notations, including natural
language, mathematics, pseudocode, executable code, various kinds of diagrams,
animations, and more.


Currently, explanation artifacts for algorithms are created ad hoc using a
variety of tools and techniques, and the resulting explanations tend to be
static, reducing their explanatory value.
%
Although there has been a substantial amount of work on algorithm
visualization~\cite{Gloor92,Gloor97,HDS02,shaffer2010algorithm,HANSEN2002291,KANN1997223},
and tools exist for creating these kinds of supporting artifacts, there is no
good solution for creating integrated, multi-notational explanations as a
whole. Similarly, although some algorithm visualization tools provide a means
for the student to tweak the parameters or inputs to an algorithm to generate
new visualizations, they do not support creating cohesive interactive
explanations that correspondingly modify the surrounding explanation or
allow the student to respond to or query the explanation in other ways.
%
To fill this gap, we envision a \emph{domain-specific language} (DSL) that
supports the creation of rich, interactive, multi-notational artifacts for
explaining algorithms.
%
The development of this DSL is part of an effort to explore the new paradigm of
\emph{explanation-oriented programming}, described in
Section~\ref{sec:back:xop}.


The intended users of the envisioned DSL are CS educators who want to create
\emph{interactive artifacts} to support the explanation of algorithms. These
users are experts on the corresponding algorithms and also skilled
programmers. The produced explanation artifacts might supplement a lecture or
be posted to a web page as a self-contained (textual and graphical)
explanation.
%
The DSL should support pedagogical methods through built-in
abstractions and language constructs. It should also support a variety of forms
of student interaction. For example, teachers should be able to define
equivalence relations enabling users to automatically generate variant
explanations~\cite{EW13jvlc}, to build in responses to anticipated
questions, and to provide explanations at multiple levels of abstraction.


This paper presents a formative step toward this vision. We conduct a
\emph{qualitative analysis} of our domain to determine the form and content of
the explanation artifacts that educators are already creating.
%
Specifically, we answer the following research questions:
%
\begin{enumerate}[label=RQ\arabic*.,ref=RQ\arabic*,leftmargin=*]

\item \label{rq:what}
%
What are the component parts of an algorithm explanation?

\item \label{rq:how}
%
How does each part advance the overall explanation?

\item \label{rq:structure}
%
How are the parts of an algorithm explanation structured?

\item \label{rq:notations}
%
What kinds of notations are used in algorithm explanations?

\end{enumerate}
%
Answers to these questions set expressiveness requirements for our DSL since we
should be able to express explanations that educators are already creating.
They also guide the design of the DSL by providing an initial set of components
and operations for building explanations.
%
We base our analysis on the established qualitative research method of
\emph{grounded theory}~\cite{Strauss67discoveryof}, described in
Section~\ref{sec:back:gt}.


For our analysis, we collected 15 explanation artifacts from the internet, as
described in Section~\ref{sec:exp:setup}. These artifacts are lecture notes
that explain two algorithms and one data structure commonly covered in
undergraduate computer science courses: Dijkstra's shortest path
algorithm~\cite[pp.~137--142]{KT06}, merge sort~\cite[pp.~210--214]{KT06}, and AVL
trees~\cite[pp.~458--475]{KnuthArt3}.
%
Applying grounded theory, we develop a coding system that
captures the components, structure, and notations of the explanation in each
document. This paper makes the following contributions:
%
\begin{enumerate}[label=C\arabic*.,ref=C\arabic*,leftmargin=*]


\item \label{contrib:codes}
%
We provide a \emph{coding system} (Section~\ref{sec:res:sys}) for analyzing
explanation artifacts in the form of lecture notes. We show that through the
application of the coding system, each artifact, regardless of content, author,
or institution, forms a tree structure, which we have termed an
\emph{explanation tree} (Section~\ref{sec:res:xopTree}).

\item \label{contrib:data}
%
We provide a coded qualitative data set of explanation artifacts, using the
system defined in \ref{contrib:codes}, applied to our sample of 15 collected
explanation artifacts, along with a tool for exploring and visualizing this
data set (Section~\ref{sec:res:data}).

\item \label{contrib:DSL}
%
We describe how our coding system and explanation trees can provide a semantic
basis for a DSL and argue for the advantages of such an approach
(Section~\ref{sec:dis}).
%
\end{enumerate}

\noindent

\section{Background And Related Work}
\label{sec:back}

In this section, we put our work into context.
%
In Section~\ref{sec:back:xop}, we describe explanation-oriented programming,
which motivates our work.
%
In Section~\ref{sec:back:gt}, we describe the grounded theory methodology that
we used to develop our coding system.
%
And in Section~\ref{sec:back:rw}, we briefly discuss other work related to
teaching algorithms.


\subsection{Explanation-Oriented Programming}
\label{sec:back:xop}

Explanation-oriented programming (XOP) is a programming paradigm where the
primary output of a program is not a set of computed values, but an
\emph{explanation of how} those values were
computed~\cite{EW08vl,EW09dsl,EW09vl,WE11dsl,EW13jvlc}.
%
A high-level goal of this work is to further realize the paradigm of XOP
through the development of a specific DSL.


Programming languages for XOP should not merely produce explanations as a
byproduct but should provide abstractions and features specific to the creation
of explanation artifacts. For example, they should provide a way to use
application-specific notations and visualizations (which are widespread in
explanations of algorithms), and to define or generate alternative explanations
in response to user input~\cite{EW13jvlc}. Additionally, languages for XOP
should help guide the programmer toward the creation of \emph{good}
explanations.


The need for interactive explanation artifacts is motivated by the observation
that there is a trade-off between personal explanations and traditional
explanation artifacts, which can be partially bridged by XOP programs viewed as
rich, interactive explanation artifacts.
%
A good \emph{personal explanation} is useful because the explainer can
\emph{respond} to the student, adjusting the pace and strategy as necessary.
For example, the teacher can answer questions, rephrase parts of an
explanation, and provide additional examples as needed.
%
Unfortunately, good personal explanations are a scarce resource. First, there
are limited number of people who can provide high quality personal explanations
on a topic. Second, a personal explanation is usually ephemeral and so cannot
be directly shared or reused.
%
Since personal explanations are hard to come by, many students learn from
\emph{impersonal explanation artifacts}, such as recorded lectures, textbooks,
and online written and graphical resources.
%
These impersonal explanations lack the interaction and adaptability of personal
explanations, but have the advantage of being easy to massively share and reuse
via libraries and the internet.


In-person lectures exist at a midway point between impersonal and personal
explanations, perhaps closer to the personal end of the spectrum. These
\emph{classroom explanations} are adaptable---students can ask questions in
class, the teacher can respond, and explanations can be adapted on the fly if
students are confused---but less so than personal explanations since the
teacher must accommodate many students at once. Classroom explanations are
shared among many students, but less shareable than impersonal explanations
since they are ephemeral and therefore difficult to reuse.


We target another midway point, closer to the impersonal end of the spectrum,
of \emph{interactive explanation artifacts} that attempt to reproduce the
responsiveness and adaptability of personal explanations, but which can still
be shared and reused online. Such explanation artifacts would be expensive to
produce with current tools since an \emph{explanation designer} must not only
create a high quality initial explanation and corresponding visualizations, but
also anticipate and explicitly program responses to queries by the student.
%
We expect that DSLs for XOP can help alleviate this burden.


\subsection{Grounded Theory}
\label{sec:back:gt}

%% What is it
The core idea of grounded theory is to generate or discover a theory
inductively, based on data, rather than using data to evaluate a theory
developed a priori. 
%
Grounded theory is rooted in a pragmatist view that theory should target its
intended uses~\cite{Strauss67discoveryof}.
%
% uses vis-a-viz logico-deductive theories which are concerned with what can be
% expressed by the theory~\cite{Strauss67discoveryof}. As Glaser and Strauss
% state:
%
% \say{A grounded theory is one that is inductively derived from the study of
% the phenomena it represents}.
%
% Like any methodology, grounded theory employs a specific vocabulary to refer
% to phases of research. The rest of this section will introduce grounded
% theory terminology in concert with an operational example that will show how
% one may perform a grounded theory analysis.
%
Our study uses the grounded theory methodology defined by
\citet{corbin2014basics}.
% This subsection briefly outlines the grounded theory methodology from
% \citet{corbin2014basics} used in our study.


Grounded theory starts by collecting initial data on the subject of interest.
For example, a researcher interested in why students drop out of computer
science programs might conduct interviews with students, and collect student
schedules and homework assignments.
%
Once some data is collected, the researcher begins \emph{coding}, which is the
process of assigning descriptive tags to qualitative data.


Coding consists of three stages:
%
\begin{enumerate*}
%
\item During \emph{open coding}, the researcher writes down \emph{any} terms
that describe the data.
%
\item During \emph{axial coding}, the researcher identifies similarities and
other relationships between tags developed during open coding. The goal of this
step is to develop a \emph{coding paradigm}, which is a model that describes
the inter-relationship of tags.
%
\item Finally, during \emph{selective coding}, the researcher identifies a
small set of core tags that capture the main concepts and relationships
identified during axial coding. These tags form the basis of the theory
extracted from the data.
%
\end{enumerate*}


In grounded theory, data collection and analysis occurs simultaneously and
iteratively. That is, after forming an initial theory, new data will be added
that might provide new tags during open coding, which will suggest revisions to
the theory developed through axial and selective coding, which will trigger a
re-analysis of old data, and so on.
%
This back-and-forth movement between data collection, analysis, and theory
building is a marked departure from quantitative methods where phases are
distinct~\cite{Strauss67discoveryof}.


How does the researcher know when the theory is adequate and no new data is
required? There are three tenets that can help answer that question, which
are pivotal to the validity of the grounded theory
method~\cite{Strauss67discoveryof}.
%
\begin{enumerate*}
%
\item The tenet of \emph{constant comparison} is that during all phases of
coding, the researcher must constantly return to earlier data to check whether
tags are applied consistently.
%
\item The tenet of \emph{theoretical sampling} focuses on filling perceived
gaps in the data based on the current theory. For example, we chose to analyze
explanations of algorithms operating on three different underlying data types:
lists, trees, and graphs. After analyzing explanations of merge sort,
explanations of other sorting algorithms have less theoretical sampling value
than explanations of a very different kind of algorithm.
%
\item The tenet of \emph{saturation} helps determine when to stop collecting
and coding new data. Saturation occurs when the coding system is able to
accommodate new data without modification. That is, when the theory can
accurately describe data that was \emph{not} used to generate it. The amount of
data needed to reach this point will vary depending on the topic, research
questions, and individual researchers.
%
\end{enumerate*}


\subsection{Teaching Algorithms through Artifacts}
\label{sec:back:rw}

% \todo{eric double check these references, most have over 100 citations, but I
%   didn't dive too deep into AV (alg vis) work because adding each reference
%   limits our space even more}

Our underlying motivation is to create artifacts that help explain algorithms.
This motivation is shared by a long tradition of researchers working on
algorithm
visualization~\cite{Gloor92,Gloor97,HDS02,shaffer2010algorithm,HANSEN2002291,
Naps:2002:ERV:782941.782998,Grissom:2003:AVC:774833.774846,KANN1997223}.
%
This work is complementary to our goal since a visualization might be one part
of a comprehensive, multi-notational explanation of an algorithm.
%
% Although our formative study considers only static explanations, our goal is to
% design a DSL that enables the creation of interactive explanation artifacts.
% Work on using puzzles~\cite{Levitin:2002:UPT:563517.563456}.
%
Although our formative study considers only static explanations in the form of
lecture notes, our ultimate goal is to design a DSL that enables the creation
of interactive explanation artifacts that realize some of the benefits of
personal explanations. Others have demonstrated that interactivity makes video
lectures a more effective pedagogical
tool~\cite{Schwan2004293,Merkt2011687,zhang2005interactive}.

% Our approach differs from other approaches~\cite{brecht2012learning,
% brecht2008enabling} to explaining algorithms, but shares many important
% features of those approaches. Algorithm visualizations and internet based
% lectures have the property of being random access i.e.\ the user may move
% forward, backward, jump around, and increase or decrease the pace, of the
% lecture at will. This property has shown to be a very effective pedagogical
% tool~\cite{cardall2008live, zhang2005interactive, zhang2006instructional,
% Schwan2004293, Merkt2011687}.
%
% While such a property ultimately comes down to the implementation of the DSL,
% we believe that the work presented here directly supports such beneficial
% aspects of previous work such as random-access and interactivity.


\section{Experimental Setup}
\label{sec:exp:setup}

In this section we describe how we executed the grounded theory process
outlined in Section~\ref{sec:back:gt}.
%
We restricted the scope of data collection to include only lecture notes
produced by faculty/instructors in computer science departments at respected
universities. Furthermore, we restrict our data to include only static, written
documents. Restricting the scope in this way has two benefits:
%
\begin{enumerate*}
%
\item All explanatory artifacts share an intrinsic goal to communicate the
mechanics, application, or implementation of a common computer science
algorithm.
%
\item There are many and varied examples of different approaches to explain the
same algorithm, and many examples of similar approaches to explain different
algorithms.
%
% \item All explanatory artifacts form isolated environments in which an
%   explanation occurs i.e. all artifacts, by virtue of being static and written,
%   must communicate in a restricted manner. In contrast, an oral explanation may
%   use tone, intonation and other forms of explanation to accentuate the
%   explanation. Including such data would complicate the
%
% \todo{fix this}
% \item The data is similar in form to the envisioned dsl i.e. the dsl is
%   envisioned as being directed towards an audience whose means of interaction
%   with it is by text. In contrast, if oral, or video explanations were included
%   than some amount of translation would be required. Although this is not
%   unreasonable it is outside the scope of this analysis.
  
\end{enumerate*}
%
All data collected was either in PDF format, or in HTML format and converted to
PDF. We considered only self-contained lecture notes, excluding slides which we
view as incomplete explanations without the associated presentation
they support. 
%
We made no attempt to restrict the size of the data collected. The smallest
document collected was 1.5 pages and the longest was 18 pages.


All data was collected and coded by hand by the first author with the aid of
Atlast.ti software.\footnote{\url{http://atlasti.com/}}
%
Atlast.ti provides direct support for the grounded theory process by allowing
open coding; easing constant comparison with operations for organizing,
searching, and filtering coded documents; and easing axial and selective coding
with operations for collecting, merging, and revising extent tags.


We focused data collection on three algorithms based on different underlying
data types: Dijkstra's shortest path algorithm on
graphs~\cite[pp.~137--142]{KT06}, merge sort of lists~\cite[210--214]{KT06},
and the AVL tree implementation of balanced binary search
trees~\cite[pp.~458--475]{KnuthArt3}.
%
We achieved saturation during the grounded theory analysis after 11 lecture
notes. As additional validation and to round out our data set, we continued
collecting and coding documents until our sample included 5 lecture notes on
each of the 3 topics, for 15 total explanation artifacts.


Some documents contain explanations of multiple algorithms. In cases where
secondary algorithms are explained as part of the explanation of the target
algorithm (e.g.\ as necessary background), we coded the explanation as usual.
In cases where multiple algorithms are explained in a single document but the
explanations are unconnected, we did not code the others. For example, one
document explaining Dijkstra's algorithm also provided an explanation of
Bellman-Ford's shortest-path algorithm, which we ignored.


% We did not perform the selective coding phase of the grounded theory
% analysis. The goal of this study was to develop a prototype coding system,
% not to develop an overarching, causal theory for these documents, such as one
% would generate in selective coding.



\section{Results}
\label{sec:res}

In this section we present the results of our grounded theory analysis.
%
In Section~\ref{sec:res:data}, we briefly describe the coded data set and a
simple associated tool that we provide.
%
In Section~\ref{sec:res:sys} we describe the coding system produced by the
grounded theory analysis and provide a sample coding to illustrate its use. We
observe that the coding paradigm identified during axial coding is that
explanations are tree structured.
%
In Section~\ref{sec:res:xopTree}, we discuss the tree structure of explanations
and describe how to transform a coded explanation artifact into the
corresponding explanation tree.


\subsection{Data Set and Tool Support}
\label{sec:res:data}

The coded data set is available online.%
\footnote{\url{https://github.com/lambda-land/XOP-Algorithms-Data}}
%
The coded documents are provided both in the proprietary Atlast.ti format and
in an exported CSV format.
%
Artifacts are indexed according to the algorithm of focus and a simple counter.
For example, the first AVL tree document is named AVT01 and the fifth is named
AVT05.


We also provide a small tool written in Haskell that implements the coding
system described in Section~\ref{sec:res:sys} and the explanation tree
representation described in Section~\ref{sec:res:xopTree}. The tool supports
converting a code sequence into the corresponding explanation tree and
rendering explanation trees in a 2-dimensional plain-text format (see
Figure~\ref{fig:tree}).
%
We provide the code sequence for each document in the data set in a format
compatible with the tool.


\subsection{The Coding System}
\label{sec:res:sys}

The coding system consists of four finite sets of tags---aspects, moves, roles,
and notations---identified by the grounded theory analysis. Aspects and moves
are summarized in Table~\ref{tbl:codes:main}, roles and notations in
Table~\ref{tbl:codes:dec}.


\begin{table}
% \begin{tabular}{>{\em}rl}
\begin{tabular}{ll}
\input{AspectTable}
\\[-1.5ex]
\input{MoveTable}
\\[-1.5ex]
\end{tabular}
\caption{Overview of all \emph{aspects} and \emph{moves} identified by the grounded theory
analysis. Aspects organize an explanation into its constituent parts while
moves are the specific steps taken to guide the reader toward understanding.}
\label{tbl:codes:main}
\vspace{-5ex}
\end{table}


An \emph{aspect} tag identifies a constituent part of an algorithm explanation,
that is, \emph{what} is being discussed (answering \ref{rq:what}). Example
aspects of an explanation are the goal of the algorithm, required operations,
historical context, advantages, disadvantages, and implementation details.
%
A \emph{move} tag is always associated with a parent aspect and describes
\emph{how} that aspect is addressed (\ref{rq:how}), that is, the step taken by
the explainer to help advance the reader's understanding. For example, by
breaking the aspect into cases, providing an example or proof, or defining a
concept. A single aspect may be explained in several moves. We take the name
for this concept from \citet{bellack1966language}'s notion of a ``pedagogical
move''.


\begin{table}
% \begin{tabular}{>{\em}rl}
\begin{tabular}{ll}
\input{RoleTable}
\\[-1.5ex]
\input{NotationTable}
\\[-1.5ex]
\end{tabular}
\caption{Overview of the secondary \emph{roles} and \emph{notations} identified
by the grounded theory analysis. These codes decorate aspect and move codes to
add additional information.}
\label{tbl:codes:dec}
\vspace{-3ex}
\end{table}


Both aspect and move tags can be decorated by tags describing secondary roles
and notations.
%
A \emph{role} tag modifies a move or aspect to indicate that this part of the
explanation serves some secondary purpose not directly captured by the modified
tag (related to both \ref{rq:how} and \ref{rq:structure}). For example,
attaching an Aside role to a move might indicate that the move is an aside that
does not directly advance the explanation of the parent aspect, while the
Pedagogical role might indicate that the move gives advice about how to study
an aspect rather than explaining it.
%
A \emph{notation} tag modifies a move or aspect to indicate that this part of
the explanation is presented in some format other than natural language text
(\ref{rq:notations}). If no notation decorator is provided, the tagged fragment
is assumed to be text.


\begin{figure}
\begin{syntax}
\multicolumn{3}{c}{
  a\in\mathit{Aspect} \quad
  m\in\mathit{Move} \quad
  r\in\mathit{Role} \quad
  n\in\mathit{Notation}} \\
c\in\mathit{Code}
 &::=& \Push~a
 \OR \!\Pop\!
 \OR m
 \OR c+d \\
d\in\mathit{Decorator}
 &::=& r \OR n
\end{syntax}
\vspace{-3ex}
\caption{Syntax of codes from grounded theory analysis.}
\label{fig:codes:syntax}
\vspace{-2ex}
\end{figure}


During axial coding, we observed that the meaning of an individual code often
depends on preceding codes. For example, a description move does not stand on
its own but typically describes a preceding aspect. 
%
Understanding how a move advances an explanation may require understanding a
sequence of preceding aspects, but not necessarily the immediately preceding
ones. For example, in AVT02 we observe the sequence \textit{data structure,
problem, solution, description, property, definition} where the final move
defines a property of the data structure; the intervening subsequence
\textit{problem, solution, description} is irrelevant to understanding the
definition but forms a separate dependency chain.
%
Thus, it seems explanations have a hierarchical structure (\ref{rq:structure})
that the coding system must capture. To do this, we introduce structuring
elements to our codes to indicate where in the hierarchy a given aspect or move
sits.


The syntax of codes is defined by the grammar in Figure~\ref{fig:codes:syntax},
which refers to the tags defined in Tables~\ref{tbl:codes:main}
and~\ref{tbl:codes:dec}.
%
A new child aspect $a$ is introduced by a ``push'' code, $\Push\,a$, and we
exit out of this aspect with a corresponding ``pop'' code, $\Pop$. A sibling
aspect can be added to the hierarchy with a pop followed by a push. Since
adding siblings is quite common, we introduce $\PopPush\,a$ as syntactic sugar
for this case.
%
A move tag $m$ is added as a child to the current aspect, which may not be the
most recent aspect named in a code due to intervening pop codes.
%
Finally, secondary roles and notations are unified as \emph{decorators}; a
decorator $d$ can be added to a code $c$ as $c+d$.


\input{sampleCoding}


In Table~\ref{tbl:sample}, we illustrate the application of the coding system
to the beginning of one of the documents in our data set, MS03.
%
The document begins in Row~1 with a header that we code as the root aspect,
representing the algorithm itself. Row~2 addresses a sub-aspect, the merge
operation, which it explains in two moves: a description, and the definition of
an in-vivo term.
%
Row~3 is coded by a pop since the explanation is no longer focused on this
operation, but is defining what merge sort is. This move is decorated by the
sequence notation since it is defined by a sequence of steps.
%
Row~4, referring to a diagram illustrating this definition, further decorates
this move with the cartoon notation.
%
Row~5 concerns the sub-aspect of motivating merge sort, which it does through a
description move that uses (light) mathematical notation.
%
Row~6 introduces the sibling aspect of disadvantages of merge sort, which is
also explained through a description with mathematical notation.



\subsection{Explanation Trees}
\label{sec:res:xopTree}

In the previous section, we described how our analysis revealed a hierarchical
structure that is crucial to understanding how an explanation does its work.
%
We call this hierarchical structure an \emph{explanation tree}. The internal
nodes of an explanation tree are the hierarchy of aspects that an explanation
addresses, while the leaves of the tree are the specific moves taken to explain
these aspects. Both the aspects and moves of an explanation tree can be
decorated by secondary roles and notations.
%
The notion of an explanation tree, discovered by considering the relationship
between adjacent moves during axial coding, became the \emph{coding paradigm}
for our analysis, so we adapted our codes to capture this structure.


Our coding system can be viewed as a simple stack-based language for
constructing an explanation tree. Figure~\ref{fig:semantics} defines an
interpretation of codes as operations in a stack-based machine that builds an
explanation tree.
%
The semantic domain of codes under this interpretation is an update function on
a stack of trees, represented as a linked list. The $\Push\,a$ code pushes a
node labeled by $a$ with no children to the stack. Note that we use $a$ to
represent both the aspect and the corresponding tree node on the stack. The
$\Pop$ code pops the first two nodes on the stack and adds the first node as a
child of the second. The $m$ code adds the move node $m$ to the stack and then
immediately executes a pop code ($\Pop$) since moves correspond to leaves in
the explanation tree.
%
In this interpretation, we assume that the codes have been preprocessed to
incorporate all decorators into the corresponding nodes.
%
Using the $\Sem{\cdot}$ function we can build an explanation tree from a
sequence of codes by simply left-folding the function over the codes with an
initially empty stack, then executing pop codes until the stack is empty.


\newcommand{\TS}{\mathit{ts}}

\begin{figure}
\[
\begin{array}{r@{}l@{~}l}
\Sem{\cdot}    &            &\,:~ \mathit{Tree}^* \to \mathit{Tree}^* \\
\Sem{\Push\,a} &(\TS)       &= a::\TS \\
\Sem{\Pop}     &(c::p::\TS) &= \mathit{addChild}(c,p)::\TS \\
\Sem{m}        &(\TS)       &= \Sem{\Pop}(m::\TS)
\end{array}
\]
\vspace{-2ex}
\caption{Interpreting codes as operations in a stack machine that builds an
explanation tree.}
\label{fig:semantics}
\vspace{-2ex}
\end{figure}


\begin{figure}
\begin{Verbatim}[fontsize=\small,xleftmargin=2ex]
Aspect Algorithm
+- Aspect Operation
|  +- Move Description
|  `- Move InVivo
+- Move Definition @ [Note Sequence,Note Cartoon]
+- Aspect Motivation
|  `- Move Description @ [Note Mathematics]
`- Aspect Disadvantage
   `- Move Description @ [Note Mathematics]
\end{Verbatim}
\vspace{-1.5ex}
\caption{Tree rendering of the codes for MS03 in Table~\ref{tbl:sample}.}
\label{fig:tree}
\vspace{-2ex}
\end{figure}


The Haskell tool provided with the data set implements the transformation from
code sequences to explanation trees. It also provides a way to render
explanation trees. This functionality is illustrated in Figure~\ref{fig:tree},
which renders the explanation tree produced by the code sequence in the coding
sample in Table~\ref{tbl:sample}.


A move at the leaf of an explanation tree can be understood to advance the
reader's understanding of the aspects along the path to a root. For example,
the last description move explains a disadvantage of the algorithm identified
by the root.
%
The linear structure of the original explanation can be recovered by a
pre-order traversal of the explanation tree. 


\section{Discussion}
\label{sec:dis}

This formative study was conducted to better understand the domain of algorithm
and data structure explanations, in order to inform the design of an
explanation-oriented DSL for creating interactive explanation artifacts. In
this section, we interpret the results from Section~\ref{sec:res} in this
context.


At a basic level, the grounded theory analysis reveals a set of concepts that
should be realized by abstractions, constructs, and features of the DSL.
%
The DSL should provide ways to capture the various aspects of an algorithm
explanation, including aspects like historical background, motivation, and
advantages/disadvantages that are typically not captured formally.
%
The DSL should also support a range of more and less formal mechanisms for
advancing an explanation through pedagogical moves. The DSL should provide
formal mechanisms for (semi\=/)automatically generating examples from
implementations, performing case-analyses and derivations, and testing
properties of an algorithm, but also support informal explanatory moves such as
presenting observations and assumptions.
%
The DSL should also provide support for a variety of different notations and
support secondary roles such as asides and caveats.


Explanation trees can serve as an underlying semantic model for the DSL.
%
In an interactive setting, explanation trees provide convenient places (nodes)
to hang extra details about an aspect that may be explored or not. Lecture
notes enforce one path through an explanation, but interactive explanations can
provide multiple paths through the same tree structure corresponding to
explanations at different levels of abstraction and with different focuses. In
addition to providing suggested paths through the tree, we can allow users to
navigate the tree on their own, exploring more details or alternative
explanations where desired.
%
The secondary roles we discovered are evidence that such supplementary
information that does not directly advance the explanation is useful. However,
there is a disincentive in a linear explanation to provide too many extra
details that detract from the main line of the explanation. These concerns
would be mitigated in an interactive setting where secondary details can be
explored on-demand and remain out-of-the-way otherwise.


A more speculative application is to use our theory to adapt and remix
explanations into new ones targeted at a specific audience or even an
individual user.
%
% Existing explanations could be in the form of coded lecture notes or
% explanations created in the future using our proposed DSL.
%
By organizing an explanation into its constituent aspects that describe
\emph{what} part of an explanation is doing, and separating this from the moves
that describe \emph{how} it is doing it, it is possible to identify other ways
of explaining the same thing.
%
% For example, suppose a user is interacting with an explanation that is less
% formal than she likes; a system could identify corresponding parts from other
% explanations that contains additional proof aspects or more math-decorated
% moves. An explanation designer could also use such a system to proactively
% identify alternative explanations to be incorporated and refined to be more
% consistent with the rest.
%
This empirical approach to generating alternative explanations can supplement
other strategies explored in previous work, such as generating alternative
explanations from equivalence laws~\cite{EW13jvlc}.


Finally, it is important to acknowledge some limitations of this work.
%
First, our results are the output of a grounded theory analysis which is
inherently subjective. Grounded theory provides a framework for systematically
extracting a theory from qualitative data (see Section~\ref{sec:back:gt}), but
the process relies on our subjective decisions about how to code the data. It
is possible that other researchers follow the same process and yet arrive at
very different results.


Another limitation is that our decision to sample only lecture notes excludes
many other ways that people already explain algorithms, such as oral or
animated explanations. We restricted our study to lecture notes because they
were easy to collect and analyze and because they represent coherent,
self-contained explanations, which is the focus of our proposed DSL. However,
unlike animations or algorithm visualization tools, lecture notes are static.
Since we aim to produce interactive explanation artifacts, it is possible we
missed important features because of this restriction.


Finally, since explanations are about communicating ideas, it is possible that
\emph{discourse analysis}~\cite{Gee14}, which focuses on extracting meaning
from \emph{how language is used}, would have been a better choice than grounded
theory. We chose grounded theory because it is a process we are familiar with
and because we anticipated coding artifacts with a variety of notations besides
natural language.



\section{Conclusion}
\label{sec:conc}

This paper presented a grounded theory analysis of 15 explanations of
algorithms and data structures in the form of lecture notes.
%
The analysis yielded a coding paradigm that organizes algorithm explanations
into explanation trees, where internal nodes represent aspects of the algorithm
and leaves represent pedagogical moves that incrementally advance the reader's
understanding.
%
We make our coded data set publicly available and provide an associated tool
for rendering the explanation tree corresponding to each document.


This study was performed as a formative domain analysis to inform the design of
a DSL for creating interactive explanations of algorithms and data structures.
Explanation trees can provide a semantic basis for such a language, and that
the enumerated aspects, moves, and roles discovered by the analysis suggest a
suite of useful constructs and abstractions the language should support and
establishes its basic expressiveness requirements.


\section*{Acknowledgments}

Thanks to Shujin Wu for helping collect data and conceptualize this work.
%
Thanks to Dan Hillman for providing data from a previous study, which we didn't
end up using but very much appreciate.


\bibliography{XOPbib,eric}
\bibliographystyle{ACM-Reference-Format}

\end{document}
