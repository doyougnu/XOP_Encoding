\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{amsmath,amssymb}
\usepackage{array}
% \usepackage{cite}   % importing cite is throwing errors for some reason
\usepackage{color}
\usepackage[inline]{enumitem}
\usepackage{multicol}
\usepackage{float}
% \usepackage[labelfont=bf,textfont=up]{caption}

\usepackage{textcomp}

% Get todos to render properly
\usepackage[obeyFinal]{easy-todo}

% Add package for well rendered quotations
\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage{lambda}

%package to handle table inputs from separate files
\usepackage{filecontents, catchfile}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% macro for angled brackets
\newcommand{\brackets}[1]{$\langle$\ignorespaces#1\unskip$\rangle$}
% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[Baltimore'2018]{SIGCSE}{February 2018}{Baltimore, Maryland USA} 
\acmYear{2018}
\copyrightyear{2017}

\acmPrice{15.00}

% inline alternative separator in grammar definitions
\newcommand{\OR}{\OB{\hspace{1.5ex}|\hspace{1.5ex}}}

% explanation tree stack operation
\newcommand{\Push}{\OB{\Rightarrow}}
\newcommand{\Pop}{\OB{\Leftarrow}}
\newcommand{\PopPush}{\OB{\Leftrightarrow}}

% semantics
\newcommand{\Sem}[1]{\OB{\llbracket#1\rrbracket}}


\begin{document}
\title{A Domain Analysis of Data Structure and Algorithm Explanations in the Wild}


% \author{Jeffrey Young} 
% \affiliation{%
%  \institution{Oregon State University}
%  \department{School of EECS}
%  \city{Corvallis} 
%  \state{Oregon}
%  \country{USA}}
% \author{Eric Walkingshaw} 
% \affiliation{%
%  \institution{Oregon State University}
%  \department{School of EECS}
%  \city{Corvallis} 
%  \state{Oregon}
%  \country{USA}}
\author{Anonymized for Review}
\affiliation{
  \institution{\phantom{Anonymous}}
  \department{\phantom{Anonymous}}
  \city{\phantom{Anonymous}}
  \state{\phantom{Anonymous}}
  \country{\phantom{Anonymous}}
}

\begin{abstract}
%
Explanations of data structures and algorithms are complex interactions of
several notations, including natural language, mathematics, pseudocode, and
diagrams. Currently, such explanations are created ad hoc using a variety of
tools and the resulting artifacts are static, reducing explanatory value. We
envision a domain-specific language for developing rich, interactive
explanations of data structures and algorithms. In this paper, we analyze this
domain to sketch requirements for our language. We perform a grounded theory
analysis to generate a qualitative coding system for explanation artifacts
collected online. This coding system implies a common structure among
explanations of algorithms and data structures. We believe this structure can
be reused as the semantic basis of a domain-specific language for creating
interactive explanation artifacts. This work is part of our effort to develop
the paradigm of explanation-oriented programming, which shifts the focus of
programming from computing results to producing rich explanations of how those
results were computed.
%
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
% \begin{CCSXML}
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}


% \keywords{ACM proceedings, \LaTeX, text tagging}

\maketitle

\section{Introduction}
\label{sec:intro}

Data structures and algorithms are at the heart of computer science and must be
explained to each new generation of students. A pressing question is: How can we
do this effectively?

In this paper, we focus on the \emph{artifacts} that constitute or support
explanations of data structures and algorithms (hereafter just ``algorithms''),
which can be shared and reused.
%
For verbal explanations, such as a lecture, the supporting artifact might be
the associated slides. For written explanations, the artifact is the
explanation as a whole, including the text and any supporting figures.
%
Explanation artifacts associated with algorithms are interesting because they
typically present a complex interaction among many different notations,
including natural language, mathematics, pseudocode, executable code, various
kinds of diagrams, animations, and more.


Currently, explanation artifacts for algorithms are created ad hoc using a
variety of tools and techniques, and the resulting explanations tend to be
static, reducing their explanatory value.
%
Although there has been a substantial amount of work on algorithm
visualization~\cite{Gloor92,Gloor97,HDS02,shaffer2010algorithm,HANSEN2002291,KANN1997223},
and tools exist for creating these kinds of supporting artifacts, there is no
good solution for creating integrated, multi-notational explanations as a
whole. Similarly, although some algorithm visualization tools provide a means
for the student to tweak the parameters or inputs to an algorithm to generate
new visualizations, they do not support creating cohesive interactive
explanations that correspondingly modify the surrounding explanation or
allow the student to respond to or query the explanation in other ways.
%
To fill this gap, we envision a \emph{domain-specific language} (DSL) that
supports the creation of rich, interactive, multi-notational artifacts for
explaining algorithms.
%
The development of this DSL is part of an effort to explore the new paradigm of
\emph{explanation-oriented programming}, described in
Section~\ref{sec:back:xop}.


The intended users of the envisioned DSL are CS educators who want to create
\emph{interactive artifacts} to support the explanation of algorithms. These
users are experts on the corresponding algorithms and also skilled
programmers. The produced explanation artifacts might supplement a lecture or
be posted to a web page as a self-contained (textual and graphical)
explanation.
%
The DSL should support pedagogical methods through built-in
abstractions and language constructs. It should also support a variety of forms
of student interaction. For example, teachers should be able to define
equivalence relations enabling users to automatically generate variant
explanations~\cite{EW13jvlc}, to build in responses to anticipated
questions, and to provide explanations at multiple levels of abstraction.


This paper represents a formative step toward this vision. We conduct a
\emph{qualitative analysis} of our domain in order to determine the form and
content of the explanation artifacts that educators are already creating.
%
We base our analysis on the established qualitative research method of
\emph{grounded theory}~\cite{Strauss67discoveryof} in order to better understand
how existing explanation artifacts explain algorithms. Our grounded theory
methodology is described in Section~\ref{sec:back:gt}.


More specifically, we collect 15 explanation artifacts from the internet, as
described in Section~\ref{sec:exp:setup}. These artifacts are lecture notes
that explain two algorithms and one data structure commonly covered in
undergraduate computer science courses: Dijkstra's shortest path
algorithm~\cite[pp.~137--142]{KT06}, merge sort~\cite[210--214]{KT06}, and AVL
trees~\cite[pp.~458--475]{KnuthArt3}.
%
Through the application of grounded theory, we develop a coding system that
captures the structure and strategy of the explanation in each document.
% An overview of the coding system is given in Section~\ref{sec:res:sys}.
This paper makes the following contributions:
%
\begin{enumerate}[label=C\arabic*.,ref=C\arabic*,leftmargin=*]

% \item \label{contrib:method}
% %
% We provide a case study on analyzing \emph{qualitative data} through the
% application of a formal research method \emph{grounded theory}.

\item \label{contrib:data}
%
We provide a coded qualitative data set of explanation artifacts, using the
system defined in \ref{contrib:codes}, applied to our sample of 15 collected
explanation artifacts, along with a tool for exploring and visualizing this
data set (Section~\ref{sec:res:data}).

\item \label{contrib:codes}
%
We provide a \emph{coding system} (Section~\ref{sec:res:sys}) for analyzing
explanation artifacts in the form of lecture notes. We show that through the
application of the coding system, each artifact, regardless of content, author,
or institution, forms a tree structure, which we have termed an
\emph{explanation tree} (Section~\ref{sec:res:xopTree}).


\item \label{contrib:DSL}
%
We describe how our coding system and explanation trees can provide a semantic
basis for a DSL and argue for the advantages of such an approach
(Section~\ref{sec:dis}).
%
\end{enumerate}

\noindent

\section{Background And Related Work}
\label{sec:back}

In this section, we put our work into context.
%
In Section~\ref{sec:back:xop}, we describe the paradigm of explanation-oriented
programming, which is the underlying motivation for our work.
%
In Section~\ref{sec:back:gt}, we describe the grounded theory methodology that
we used to develop our coding system.
%
And in Section~\ref{sec:back:rw}, we briefly discuss other work related to
teaching algorithms.


\subsection{Explanation-Oriented Programming}
\label{sec:back:xop}

Explanation-oriented programming (XOP) is a programming paradigm where the
primary output of a program is not a set of computed values, but an
\emph{explanation of how} those values were
computed~\cite{EW08vl,EW09dsl,EW09vl,WE11dsl,EW13jvlc}.
%
A high-level goal of this work is to further realize the paradigm of XOP
through the development of a specific DSL.


Programming languages for XOP should not merely produce explanations as a
byproduct, but should provide abstractions and features specific to the
creation of interactive explanation artifacts. For example, they should provide
facilities for creating application-specific notations and visualizations
(which are widespread in explanations of algorithms), and for describing
alternative explanations produced in response to user input, for example, at
different levels of abstraction, by parameterization, or generated by
explanation equivalence laws~\cite{EW13jvlc}. Additionally, languages for XOP
should help guide the programmer toward the creation of \emph{good}
explanations.


The need for interactive explanation artifacts is motivated by the observation
that there is a trade-off between personal explanations and traditional
explanation artifacts, which can be partially bridged by XOP programs viewed as
rich, interactive explanation artifacts.
%
A good \emph{personal explanation} is useful because the explainer can
\emph{respond} to the student, adjusting the pace and strategy as necessary.
For example, the teacher can answer questions, rephrase parts of an
explanation, and provide additional examples as needed.
%
Unfortunately, good personal explanations are a scarce resource. First, there
are limited number of people who can provide high quality personal explanations
on a topic. Second, a personal explanation is usually ephemeral and so cannot
be directly shared or reused.
%
Since personal explanations are hard to come by, many students learn from
\emph{impersonal explanation artifacts}, such as recorded lectures, textbooks
and online written and graphical resources.
%
These impersonal explanations lack the interaction and adaptability of personal
explanations, but have the advantage of being easy to massively share and reuse
via libraries and the internet.


In-person lectures, such as those covering algorithms in most undergraduate
computer science programs, exist at a midway point between impersonal and
personal explanations, perhaps closer to the personal end of the spectrum.
These \emph{classroom explanations} are adaptable---students can ask questions
in class, the teacher can respond, and explanations can be adapted on the fly
if students are confused---but they are not as adaptable as personal
explanations since the teacher must accommodate many students at once.
Classroom explanations are more efficient than personal explanations since they
are shared amongst many students, but not as efficient as impersonal
explanations since they are still ephemeral and therefore difficult to reuse.


We target another midway point, a bit closer to the impersonal end of the
spectrum, of \emph{interactive explanation artifacts} that provide as much of
the responsiveness and adaptability of personal explanations as possible, but
which can still be massively shared and reused online. Such an explanation
artifact would be quite expensive to produce with current tools since an
\emph{explanation designer} must not only construct a high quality initial
explanation and corresponding visualizations, but also anticipate and
explicitly program in responses to queries by the student.
%
We expect that DSLs for XOP can help alleviate this burden.


\subsection{Grounded Theory}
\label{sec:back:gt}

%% What is it
The central idea behind grounded theory is to generate or discover a theory
inductively, \emph{based on data}, rather than the usual scientific approach of
using data to evaluate a theory developed a priori. 
%
Grounded theory is rooted in a \emph{pragmatist} view that theory should be
targeted at its intended uses~\cite{Strauss67discoveryof}.
%
% uses vis-a-viz logico-deductive theories which are concerned with what can be
% expressed by the theory~\cite{Strauss67discoveryof}. As Glaser and Strauss
% state:
%
% \say{A grounded theory is one that is inductively derived from the study of
% the phenomena it represents}.
%
% Like any methodology, grounded theory employs a specific vocabulary to refer
% to phases of research. The rest of this section will introduce grounded
% theory terminology in concert with an operational example that will show how
% one may perform a grounded theory analysis.
%
The rest of this section briefly outlines the grounded theory methodology from
\citet{corbin2014basics} that we used in this formative study.


The first task in grounded theory is to collect initial data from the subject
one wishes to study. For example, a researcher who wants to find out why some
students drop out of computer science programs might conduct interviews with
students, and collect student schedules and homework assignments.
%
Once some data is collected, the researcher begins \emph{coding}, which is the
process of assigning descriptive tags to qualitative data.


Coding consists of three stages:
%
\begin{enumerate*}
%
\item In the \emph{open coding} stage, the researcher writes down \emph{any}
terms that describe the data.
%
\item In the \emph{axial coding} stage, the researcher identifies similarities
and other relationships between the tags developed during open coding. The goal
of this step is to develop a \emph{coding paradigm}, which is a model that
describes the inter-relationship between tags.
%
\item Finally, in the \emph{selective coding} stage, the researcher tries to
identify a small set of core tags that capture the main concepts and
relationships identified during axial coding. These tags form the basis of the
theory extracted from the data.
%
\end{enumerate*}


In grounded theory, data collection and analysis occurs simultaneously and
iteratively. That is, after forming an initial theory, new data will be added
that might provide new tags during open coding, which will suggest revisions to
the theory developed through axial and selective coding, which will trigger a
re-analysis of old data, and so on.
%
This movement back-and-forth between data collection, analysis, and theory
building is a marked departure from quantitative methods where phases are
distinct~\cite{Strauss67discoveryof}.


How does the researcher know when the theory is adequate and when to stop
collecting and coding new data? There are three tenets that can help answer
that question, and which are pivotal to the validity of the grounded theory
method~\cite{Strauss67discoveryof}.
%
\begin{enumerate*}
%
\item The tenet of \emph{constant comparison} is that during all phases of
coding, the researcher must constantly return to earlier data to check whether
tags are applied consistently.
%
\item The tenet of \emph{theoretical sampling} focuses on filling perceived
gaps in the data based on the current theory. For example, we chose to analyze
explanations of algorithms operating on three different underlying data types:
lists, trees, and graphs. After analyzing explanations of merge sort,
explanations of other sorting algorithms have less theoretical sampling value
than explanations of a very different kind of algorithm.
%
\item The tenet of \emph{saturation} helps determine when to stop collecting
and coding new data. Saturation occurs when the coding system is able to
accommodate new data without modification. That is, when the theory can
accurately describe data that was \emph{not} used to generate it. The amount of
data needed to reach this point will vary depending on the topic, research
questions, and individual researchers.
%
\end{enumerate*}


\subsection{Teaching Algorithms through Artifacts}
\label{sec:back:rw}

% \todo{eric double check these references, most have over 100 citations, but I
%   didn't dive too deep into AV (alg vis) work because adding each reference
%   limits our space even more}

Our underlying motivation is to create artifacts that help explain algorithms.
This motivation is shared by a long tradition of researchers working on
algorithm
visualization~\cite{Gloor92,Gloor97,HDS02,shaffer2010algorithm,HANSEN2002291,
Naps:2002:ERV:782941.782998,Grissom:2003:AVC:774833.774846,KANN1997223}.
%
This work is complementary to our goal since a visualization might be one part
of a comprehensive, multi-notational explanation of an algorithm.
%
% Although our formative study considers only static explanations, our goal is to
% design a DSL that enables the creation of interactive explanation artifacts.
% Work on using puzzles~\cite{Levitin:2002:UPT:563517.563456}.
%
Although our formative study considers only static explanations in the form of
lecture notes, our ultimate goal is to design a DSL that enables the creation
of interactive explanation artifacts that realize some of the benefits of
personal explanations. Others have demonstrated that interactivity makes video
lectures a more effective pedagogical
tool~\cite{Schwan2004293,Merkt2011687,zhang2005interactive}.

% Our approach differs from other approaches~\cite{brecht2012learning,
% brecht2008enabling} to explaining algorithms, but shares many important
% features of those approaches. Algorithm visualizations and internet based
% lectures have the property of being random access i.e.\ the user may move
% forward, backward, jump around, and increase or decrease the pace, of the
% lecture at will. This property has shown to be a very effective pedagogical
% tool~\cite{cardall2008live, zhang2005interactive, zhang2006instructional,
% Schwan2004293, Merkt2011687}.
%
% While such a property ultimately comes down to the implementation of the DSL,
% we believe that the work presented here directly supports such beneficial
% aspects of previous work such as random-access and interactivity.


\section{Experimental Setup}
\label{sec:exp:setup}

In this section we describe how we executed the grounded theory process
outlined in Section~\ref{sec:back:gt}.
%
We restricted the scope of data collection to include only lecture notes
produced by faculty/instructors in computer science departments at respected
universities. Restricting the scope in this way has two benefits:
%
\begin{enumerate*}
%
\item All explanatory artifacts share an intrinsic goal to communicate the
mechanics, application, or implementation of some common computer science
algorithm.
%
\item There are many and varied examples of different approaches to explain the
same algorithm, and many examples of similar approaches to explain different
algorithms.
%
\end{enumerate*}
%
All data collected was either in PDF format, or in HTML format and converted to
PDF. We considered only self-contained lecture notes, excluding slides which we
considered to be incomplete explanations without the associated presentation
they support.
%
We made no attempt to restrict the size of the data collected. The smallest
document collected was 1.5 pages and the longest was 18 pages.


All data was collected and coded by hand by a single researcher with the aid of
Atlast.ti software.\footnote{\url{http://atlasti.com/}}
%
Atlast.ti provides direct support for the grounded theory process by allowing
open coding; easing constant comparison with operations for organizing,
searching, and filtering coded documents; and easing axial and selective coding
with operations for collecting, merging, and revising extent tags.


We focused data collection on three algorithms based on different underlying
data types: Dijkstra's shortest path algorithm on
graphs~\cite[pp.~137--142]{KT06}, merge sort of lists~\cite[210--214]{KT06},
and the AVL tree implementation of balanced binary search
trees~\cite[pp.~458--475]{KnuthArt3}.
%
We achieved saturation during the grounded theory analysis after 11 lecture
notes. As additional validation and to round out our data set, we continued
collecting and coding documents until our sample included 5 lecture notes on
each of the 3 topics, for 15 total explanation artifacts.


Some documents contain explanations of multiple algorithms. In cases where
secondary algorithms are explained as part of the explanation of the target
algorithm (e.g.\ as necessary background), we coded the explanation as usual.
In cases where multiple algorithms are explained in a single document but the
explanations are unconnected, we did not code the others. For example, one
document explaining Dijkstra's algorithm also provided an explanation of
Bellman-Ford's shortest-path algorithm, which we ignored.


% We did not perform the selective coding phase of the grounded theory
% analysis. The goal of this study was to develop a prototype coding system,
% not to develop an overarching, causal theory for these documents, such as one
% would generate in selective coding.



\section{Results}

In this section we present the results of our grounded theory analysis.
%
In Section~\ref{sec:res:data}, we briefly describe the coded data set and a
simple associated tool that we provide.
%
In Section~\ref{sec:res:sys} we describe the coding system produced by the
grounded theory analysis and provide a sample coding to illustrate its use. We
observe that the coding paradigm identified during axial coding is that
explanations are tree structured.
%
In Section~\ref{sec:res:xopTree}, we discuss the tree structure of explanations
and describe how to transform a coded explanation artifact into the
corresponding explanation tree.


\subsection{Data Set and Tool Support}
\label{sec:res:data}

The coded data set is available online.\footnote{Will be made available after
anonymous review.} The coded documents are provided both in the proprietary
Atlast.ti format and in an exported CSV format.
%
Artifacts are indexed according to the algorithm of focus and a simple counter.
For example, the first AVL tree document is named AVT01 and the fifth is named
AVT05.


We also provide a small tool written in Haskell that implements the coding
system described in Section~\ref{sec:res:sys} and the explanation tree
representation described in Section~\ref{sec:res:xopTree}. The tool supports
converting a code sequence into the corresponding explanation tree, and
rendering explanation trees in a 2-dimensional plain-text format (see
Figure~\ref{fig:tree}).
%
We provide the code sequence for each document in the data set in a format
compatible with the tool.


\subsection{The Coding System}
\label{sec:res:sys}

The coding system consists of four finite sets of tags---aspects, moves, roles,
and notations---determined through the grounded theory analysis. Aspects and
moves are summarized in Table~\ref{tbl:codes:main}, roles and notations in
Table~\ref{tbl:codes:dec}.


\begin{table}
% \begin{tabular}{>{\em}rl}
\begin{tabular}{ll}
\input{AspectTable}
\\[-1.5ex]
\input{MoveTable}
\\[-1.5ex]
\end{tabular}
\caption{Overview of all \emph{aspects} and \emph{moves} identified by the grounded theory
analysis. Aspects organize an explanation into its constituent parts while
moves are the specific steps taken to guide the reader toward understanding.}
\label{tbl:codes:main}
\end{table}


An \emph{aspect} tag identifies a constituent part of an algorithm explanation,
that is, \emph{what} is being discussed. Example aspects of an explanation are
the goal of the algorithm, required operations, historical context, advantages
and disadvantages, and implementation details.
%
A \emph{move} tag is always associated with a parent aspect and describes
\emph{how} that aspect is addressed, that is, the step taken by the explainer
to help advance the reader's understanding. For example, by breaking the aspect
into cases, providing an example or proof, or defining a concept. A single
aspect may be explained in several moves. We take the name for this concept
from \citet{bellack1966language}'s notion of a ``pedagogical move''.


\begin{table}
% \begin{tabular}{>{\em}rl}
\begin{tabular}{ll}
\input{RoleTable}
\\[-1.5ex]
\input{NotationTable}
\\[-1.5ex]
\end{tabular}
\caption{Overview of the secondary \emph{roles} and \emph{notations} identified
by the grounded theory analysis. These codes decorate aspect and move codes to
add additional information.}
\label{tbl:codes:dec}
\end{table}


Both aspect and move tags can be decorated by tags describing secondary roles
and notations.
%
A \emph{role} tag modifies a move or aspect to indicate that this part of the
explanation serves some secondary purpose not directly captured by the modified
tag. For example, the Aside role might be attached to a move to indicate that
the given move is an aside that does not directly advance the explanation of
the parent aspect, while the Pedagogical role might indicate that the move
gives advice about how to study an aspect rather than explaining it.
%
A \emph{notation} tag modifies a move or aspect to indicate that this part of
the explanation is presented in some format other than natural language text.
If no notation decorator is provided, the tagged fragment is assumed to be
text.


\begin{figure}
\begin{syntax}
\multicolumn{3}{c}{
  a\in\mathit{Aspect} \quad
  m\in\mathit{Move} \quad
  r\in\mathit{Role} \quad
  n\in\mathit{Notation}} \\
c\in\mathit{Code}
 &::=& \Push~a
 \OR \!\Pop\!
 \OR m
 \OR c+d \\
d\in\mathit{Decorator}
 &::=& r \OR n
\end{syntax}

\vspace{-1.5ex}
\caption{Syntax of codes from grounded theory analysis.}
\label{fig:codes:syntax}
\end{figure}


The syntax of codes in our system is defined by the grammar in
Figure~\ref{fig:codes:syntax}, which refers to the tags defined in
Tables~\ref{tbl:codes:main} and~\ref{tbl:codes:dec}.
%
During axial coding, it was realized that aspects of an explanation are
hierarchically arranged, and that in many cases it is only possible to
understand how a move advances an explanation by considering not only the
parent aspect but also its ancestors.
%
Therefore, the coding system needs a way to capture this hierarchy. To do this,
we introduced structuring elements to our codes for indicating where in the
hierarchy a given aspect sits.
%
A new child aspect $a$ is introduced by a ``push'' code, $\Push\,a$, and we
exit out of this aspect with a corresponding ``pop'' code, $\Pop$. A sibling
aspect can be added to the hierarchy with a pop followed by a push. Since
adding siblings is quite common, we introduce $\PopPush\,a$ as syntactic sugar
for this case.
%
A move tag $m$ is added as a child to the current aspect, which may not be the
most recent aspect named in a code due to intervening pop codes.
%
Finally, secondary roles and notations are unified as \emph{decorators}; a
decorator $d$ can be added to a code $c$ as $c+d$.


\input{sampleCoding}


In Table~\ref{tbl:sample}, we illustrate the application of the coding system
to the beginning of one of the documents in our data set, MS03.
%
The document begins in Row~1 with a header that we code as the root aspect,
representing the algorithm itself. Row~2 addresses a sub-aspect, the merge
operation, which it explains in two moves: a description, and the definition of
an in-vivo term.
%
Row~3 is coded by a pop since the explanation is no longer focused on this
operation, but is defining what merge sort is. This move is decorated by the
sequence notation since it is defined by a sequence of steps.
%
Row~4, referring to a diagram illustrating this definition, further decorates
this move with the cartoon notation.
%
Row~5 concerns the sub-aspect of motivating merge sort, which it does through a
description move that uses (light) mathematical notation.
%
Row~6 introduces the sibling aspect of disadvantages of merge sort, which is
also explained through a description with mathematical notation.



\subsection{Explanation Trees}
\label{sec:res:xopTree}

In the previous section, we described how our analysis revealed a hierarchical
structure that is crucial to understanding how an explanation does its work.
%
We call this hierarchical structure an \emph{explanation tree}. The internal
nodes of an explanation tree are the hierarchy of aspects that an explanation
addresses, while the leaves of the tree are the specific moves taken to explain
these aspects. Both the aspects and moves of an explanation tree can be
decorated by secondary roles and notations.
%
The notion of an explanation tree, discovered during axial coding, became the
\emph{coding paradigm} for our analysis, so we adapted our codes to capture
this structure.


Our coding system can be viewed as a simple stack-based language for
constructing an explanation tree. Figure~\ref{fig:semantics} defines an
interpretation of codes as operations in a stack-based machine that builds an
explanation tree.
%
The semantic domain of codes under this interpretation is an update function on
a stack of trees, represented as a linked list. The $\Push\,a$ code pushes a
node labeled by $a$ with no children to the stack. Note that we use $a$ to
represent both the aspect and the corresponding tree node on the stack. The
$\Pop$ code pops the first two nodes on the stack and adds the first node as a
child of the second. The $m$ code adds the move node $m$ to the stack and then
immediately executes a pop code ($\Pop$) since moves correspond to leaves in
the explanation tree.
%
In this interpretation, we assume that the codes have been preprocessed to
incorporate all decorators into the corresponding nodes.
%
Using the $\Sem{\cdot}$ function we can build an explanation tree from a
sequence of codes by simply left-folding the function over the codes with an
initially empty stack, then executing pop codes until the stack is empty.


\newcommand{\TS}{\mathit{ts}}

\begin{figure}
\[
\begin{array}{r@{}l@{~}l}
\Sem{\cdot}    &            &\,:~ \mathit{Tree}^* \to \mathit{Tree}^* \\
\Sem{\Push\,a} &(\TS)       &= a::\TS \\
\Sem{\Pop}     &(c::p::\TS) &= \mathit{addChild}(c,p)::\TS \\
\Sem{m}        &(\TS)       &= \Sem{\Pop}(m::\TS)
\end{array}
\]
\vspace{-1.5ex}
\caption{Interpreting codes as operations in a stack machine that builds an
explanation tree.}
\label{fig:semantics}
\end{figure}


\begin{figure}
\begin{Verbatim}[fontsize=\small,xleftmargin=2ex]
Aspect Algorithm
+- Aspect Operation
|  +- Move Description
|  `- Move InVivo
+- Move Definition @ [Note Sequence,Note Cartoon]
+- Aspect Motivation
|  `- Move Description @ [Note Mathematics]
`- Aspect Disadvantage
   `- Move Description @ [Note Mathematics]
\end{Verbatim}
\caption{Rendering of the explanation tree produced by the coding of the
beginning of MS03 given in Table~\ref{tbl:sample}.}
\label{fig:tree}
\end{figure}


The Haskell tool provided with the data set implements the transformation from
code sequences to explanation trees. It also provides a way to render
explanation trees. This functionality is illustrated in Figure~\ref{fig:tree},
which renders the explanation tree produced by the code sequence in the coding
sample in Table~\ref{tbl:sample}.


A move at the leaf of an explanation tree can be understood to advance the
reader's understanding of the aspects along the path to a root. For example,
the last description move explains a disadvantage of the algorithm identified
by the root.
%
The linear structure of the original explanation can be recovered by a
pre-order traversal of the explanation tree. 


\section{Discussion of Results}
\label{sec:dis}
In this section we summarize and interpret the results presented above. In
section \ref{sec:dis:model} we describe the benefits of translating explanation
artifacts into explanation trees. Section \ref{sec:dis:expr} reflects on
supporting varied expressions of like content and section \ref{sec:dis:tail}
discusses the support of tailored, adaptive, explanations. Although we posit
several benefits to using work presented in this paper, all such benefits are
merely conjectures until such a DSL, as is referenced throughout this paper, is
created. \todo{where do we say this line}

The central problem with designing and constructing an explanation-oriented DSL
is translating explanations into an abstract computational model. Several issues
immediately arise with such an approach: 1) What is an \emph{explanation} and
how does one model it as a computational concept? 2) How does one react to user
input? 3) How does one capture varied notation? 4) Similarly, how does one
capture the flexibility and robustness of tailored explanations. Throughout this
section we refer to the \emph{consumer} of an explanation to mean the end
audience for an explanation that the user of the DSL creates.

\subsection{Advantages of an Abstract Model}
\label{sec:dis:model}

% Problem 1
Rather than delving into the yawning maw of philosophy of
explanation~\cite{sep-scientific-explanation} we offload such concerns to the
prospective user's of the DSL. The remaining issues, we believe, are
significantly alleviated with explanation trees.

% Problem 2
In order to support interaction with a consumer a DSL must have an abstract
model with which the user, and consumer may interact with. Explanation trees
directly enable this type of behavior by providing an abstract model of an
explanation artifact.
%
By distilling an explanation artifact into an explanation tree, a user may
create an explanation that matches, and extends, the interactivity with static
documents. For example, a user may want to create an explanation of the
mergesort algorithm; which would correspond directly with a translation of an
explanation artifact to an explanation tree. The user may then anticipate
inquires into other topics related to mergesort but that are not covered in
static documents, such as computational complexity or array data structures.

Because explanation trees are, in essence, abstract models of explanations, one
could imagine the user adding special edges or \emph{links} to support such
inquires. Then if a consumer of the explanation inquired about computational
complexity, the explanation could traverse such a link to the explanation tree
for computational complexity. Such features are simply not possible with
traditional static documents.

Furthermore, the benefits of an abstract model is that one is now able to
compare, abstractly, different explanations for like things. In fact, one may
envision having database of explanations for like things which could be used to
formulate a \emph{general explanation} for a given topic. Such a database would
have more advantages, some of which are described below.

\subsection{Handling Content Expression}
\label{sec:dis:expr}
% Problem 3
A trivial examination of explanation artifacts or any experience in academia
reveals that like things are explained using varied and eclectic notations. The
notations encompassed in the coding system are unlikely to be an exhaustive list
of all such notations.

Content is orthogonal to expression in an explanation tree, thus content may
therefore be separated from notation, and the expression of content in an
explanation tree is extensible. A thorough or meticulous user may wish to create
explanations that can express content with varied notations. Such a user may
provide their explanations with a textual expression, a cartoon expression or a
mathematical formulation, all notations are viable because of the separation of
content and content expression. Such features are currently matched by
traditional static documents. An explanation-oriented DSL, that operates on
explanation trees, could support expressing a single aspect (a single node in
the explanation tree) with different expressions, thereby increasing the options
available to DSL users and explanation consumers.

For example, a DSL user may provide a code based expression for the relax
operation in Dijkstra's algorithm, but they may also provide an auxiliary
cartoon based expression. The addition of an auxiliary expression could then be
requested by an explanation consumer. Technically, the explanation-tree would
simply have another expression tag applied to the same node. This feature, the
ability to express the same content, in many notations, at the request of the
explanation consumer, is only observed in in-person explanations. \todo{this probably
  needs work}

% Problem 4
\subsection{Towards Tailored Computational Explanation}
\label{sec:dis:tail}
The last issue with an explanation-oriented DSL is that of supporting tailored
explanation. This problem essentially boils down to adapting, in real time, to
an explanation consumer. While support for such a feature will hinge on the
interaction semantics available to the consumer, we view explanation trees as
being a significant step in the right direction.

Serving as an abstract model, it becomes possible to collect several explanation
artifacts of like content, much like the data used in this study. By having a
database of such artifacts a user could construct an explanation that draws upon
several explanation artifacts except just one, as is the case with current
static \emph{and} interactive tools. Thus, if a consumer becomes stuck on a
at some point of an explanation, they may switch to the corresponding point in
another explanation and attempt to proceed from there, or consume only that
node, and then return to the previous explanation. While this is still far from
competing with a one-on-one tutorship on the material, such a feature is simply
impossible with static documents and represents a step toward more interactivity.

\section{Conclusion and Future Work}

\todo{write conclusion}
As described in the previous section, we believe that this work offers several
avenues of continued research. First an foremost is to begin writing a DSL based
on the results presented here. Several aspects of the DSL are abstract; for
instance the semantics of interaction, and the user interface. These aspects of
the DSL are likely to remain open questions until an implementation is created. 

The coding system is, admittedly, based on few raw documents. While we reached
saturation with only eleven documents, there is always a risk that the coding
system is not transferable to other computer science content. Thus, more coding,
with varied content is pivotal to validate that the coding system can actually
express radically different content then that which it is grounded in.
\todo{what else?}

\bibliography{XOPbib,eric}
\bibliographystyle{ACM-Reference-Format}

\end{document}
